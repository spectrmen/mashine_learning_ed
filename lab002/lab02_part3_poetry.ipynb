{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spectrmen/mashine_learning_ed/blob/main/lab002/lab02_part3_poetry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_3v-Foh6aUq"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmXRiUjv6aUr"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs.\n",
        "\n",
        "You have several choices here:\n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UBn-i2et6aUs"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --upgrade sympy -q"
      ],
      "metadata": {
        "id": "87p3QGTnNjPL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmL-Nv6w6aUt"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDbANWVc6aUt"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpL0Yg1b6aUt",
        "outputId": "841c2066-183e-45c5-a11e-43f8e25486c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1718"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://github.com/dfinke/Tiny-PowerShell-Projects/blob/ecc1c625d9e58708c911f08b9fc14eee885aae78/inputFiles/sonnets.txt#L4\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "\n",
        "text = [x.replace('\\t\\t', '') for x in text]\n",
        "text = [x.replace('\\n', '') for x in text]\n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "len(text) == 2616\n",
        "len(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_51JJCx06aUu"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkWWbmyN6aUu",
        "outputId": "8b82b97f-7c98-44d1-ab52-357fb3769263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK!\n"
          ]
        }
      ],
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "text = ''.join(text).lower()\n",
        "\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STZJIzIh6aUu"
      },
      "source": [
        "### Data loading: \"Евгений Онегин\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1XMn_tr6aUu",
        "outputId": "e2066a3f-9a2b-4344-e56c-679f6b2f7901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-11 16:24:40--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt.1’\n",
            "\n",
            "\ronegin.txt.1          0%[                    ]       0  --.-KB/s               \ronegin.txt.1        100%[===================>] 256.37K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-12-11 16:24:40 (9.13 MB/s) - ‘onegin.txt.1’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "\n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "text = [x.replace('\\t\\t', '') for x in text]\n",
        "text = [x.replace('\\n', '') for x in text]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dCYy-UYESBW7",
        "outputId": "a16a7338-1d71-403e-85b6-3c50f9b2aefc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i«мой дядя самых честных правил,когда не в шутку занемог,он уважать себя заставили лучше выдумать не мог.его пример другим наука;но, боже мой, какая скукас больным сидеть и день и ночь,не отходя ни шагу прочь!какое низкое коварствополуживого забавлять,ему подушки поправлять,печально подносить лекарс'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zj9MifK6aUv"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lVvTVvTv6aUv"
      },
      "outputs": [],
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "text = ''.join(text).lower()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GakXZJzB6aUv"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3yZLO-3y6aUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7f272e4a-ec85-4f88-d5a9-5f9c3570e26b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '5',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " '[',\n",
              " ']',\n",
              " '^',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '«',\n",
              " '»',\n",
              " 'а',\n",
              " 'б',\n",
              " 'в',\n",
              " 'г',\n",
              " 'д',\n",
              " 'е',\n",
              " 'ж',\n",
              " 'з',\n",
              " 'и',\n",
              " 'й',\n",
              " 'к',\n",
              " 'л',\n",
              " 'м',\n",
              " 'н',\n",
              " 'о',\n",
              " 'п',\n",
              " 'р',\n",
              " 'с',\n",
              " 'т',\n",
              " 'у',\n",
              " 'ф',\n",
              " 'х',\n",
              " 'ц',\n",
              " 'ч',\n",
              " 'ш',\n",
              " 'щ',\n",
              " 'ъ',\n",
              " 'ы',\n",
              " 'ь',\n",
              " 'э',\n",
              " 'ю',\n",
              " 'я',\n",
              " 'ё',\n",
              " '–',\n",
              " '—',\n",
              " '’',\n",
              " '…',\n",
              " '€',\n",
              " ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tokens = sorted(set(text))[1:]\n",
        "tokens.append(' ')\n",
        "\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS6zBxeG6aUv"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "L0tLM-Mh6aUv"
      },
      "outputs": [],
      "source": [
        "# dict <index>:<char>\n",
        "idx_to_token = {idx: token for idx, token in enumerate(tokens)}\n",
        "\n",
        "# dict <char>:<index>\n",
        "token_to_idx = {token: idx for idx, token in enumerate(tokens)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxArs6BF6aUv"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJne0xWw6aUv"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNmOkuAg6aUw"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhrB3ydO6aUw",
        "outputId": "f2392287-c0a9-4beb-fe02-b6829647e2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.5053\n",
            "Epoch 2/10, Loss: 2.2376\n",
            "Epoch 3/10, Loss: 2.1329\n",
            "Epoch 4/10, Loss: 2.0652\n",
            "Epoch 5/10, Loss: 2.0185\n",
            "Epoch 6/10, Loss: 1.9818\n",
            "Epoch 7/10, Loss: 1.9534\n",
            "Epoch 8/10, Loss: 1.9277\n",
            "Epoch 9/10, Loss: 1.9067\n",
            "Epoch 10/10, Loss: 1.8887\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "SEQ_LENGTH = 50\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 2\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10\n",
        "MAX_LENGTH = 500\n",
        "\n",
        "# Convert text to indices\n",
        "text_indices = [token_to_idx[char] for char in text]\n",
        "\n",
        "# Create sequences\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(text_indices) - SEQ_LENGTH):\n",
        "    X.append(text_indices[i:i+SEQ_LENGTH])\n",
        "    y.append(text_indices[i+SEQ_LENGTH])\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.long)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = torch.utils.data.TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Define RNN model\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x shape: (batch, seq_len)\n",
        "        x = self.embedding(x)  # (batch, seq_len, hidden_size)\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        # Take the last output\n",
        "        out = out[:, -1, :]  # (batch, hidden_size)\n",
        "        out = self.fc(out)  # (batch, vocab_size)\n",
        "        return out, hidden\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "\n",
        "# Initialize model\n",
        "char_rnn = CharRNN(len(tokens), HIDDEN_SIZE, NUM_LAYERS)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(char_rnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training\n",
        "losses = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        hidden = char_rnn.initial_state(batch_X.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, hidden = char_rnn(batch_X, hidden)\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "print('Training completed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX6TON3c6aUw"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "Ip9vkEUk6aUw",
        "outputId": "f2194d78-c895-45e6-9ee7-6b2de2f7cca1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the loss function\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, NUM_EPOCHS + 1), losses, 'b-', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training Loss (Vanilla RNN)', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-RumRnC69Gvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OdJNmXPR9HSG"
      },
      "outputs": [],
      "source": [
        "def generate_sample(model, seed_phrase=' hello', max_length=MAX_LENGTH, temperature=1.0):\n",
        "    '''\n",
        "    ### Disclaimer: this is an example function for text generation.\n",
        "    ### You can either adapt it in your code or create your own function\n",
        "\n",
        "    The function generates text given a phrase. Works with both RNN and LSTM models.\n",
        "    :param model: trained RNN or LSTM model (CharRNN or CharLSTM)\n",
        "    :param seed_phrase: prefix characters. The model is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "        smaller temperature converges to the single most likely output.\n",
        "\n",
        "    Be careful with the model output. This model waits logits (not probabilities/log-probabilities)\n",
        "    of the next symbol.\n",
        "    '''\n",
        "    # Remember current mode and switch to eval for generation\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Convert seed phrase to indices\n",
        "        x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "        x_sequence = torch.tensor([x_sequence], dtype=torch.long)\n",
        "\n",
        "        # Initialize hidden state (works for both RNN and LSTM)\n",
        "        hid_state = model.initial_state(batch_size=1)\n",
        "\n",
        "        # Feed the seed phrase, if any\n",
        "        if len(seed_phrase) > 1:\n",
        "            for i in range(len(seed_phrase) - 1):\n",
        "                out, hid_state = model(x_sequence[:, i:i+1], hid_state)\n",
        "\n",
        "        # Start generating\n",
        "        for _ in range(max_length - len(seed_phrase)):\n",
        "            out, hid_state = model(x_sequence[:, -1:], hid_state)\n",
        "            # Be really careful here with the model output\n",
        "            p_next = F.softmax(out / temperature, dim=-1).data.numpy()[0]\n",
        "\n",
        "            # Sample next token and push it back into x_sequence\n",
        "            next_ix = np.random.choice(len(tokens), p=p_next)\n",
        "            next_ix = torch.tensor([[next_ix]], dtype=torch.long)\n",
        "            x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    # Restore original mode explicitly using a boolean\n",
        "    model.train(mode=bool(was_training))\n",
        "    return ''.join([idx_to_token[ix] for ix in x_sequence.data.numpy()[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "zT3ymVz-6aUw",
        "outputId": "8c9304f7-5ff1-42a8-870b-e8ae904a25eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'skull and bonsert?vvil[ъмаетв, острестей,стекра обманыхорьком, быно,и чувств,говорящуж лерся, розадцатом занять наши простор,кудра намяодо? что в меня.теперь;ольдыпредвир,и с волзлаю;которы от сешенствая пред герородит выпучьеегею пречулие из и егоседь можныйонего мона,у врага,как бегаком не сладу,сезяторил пробожу я теперь гивойпоздравты розыславно предскают провид,где вы поздна?что жаже нет старуxка,но признажет луна,иль,дверою слажен, в лед.в малый вдохачно семди мерглаяна,что года в далеко п'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "generate_sample(char_rnn,seed_phrase='skull and bons', max_length=500)\n",
        "# An example of generated text.\n",
        "# print(generate_text(length=500, temperature=0.2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vfm5rDTRdvmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "8c2a4ad1-5ee7-4a67-a621-fb9fe9d784db",
        "id": "3nEad98uFrK1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-875106611.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "SEQ_LENGTH = 50\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 2\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 20\n",
        "MAX_LENGTH = 500\n",
        "\n",
        "# Convert text to indices\n",
        "text_indices = [token_to_idx[char] for char in text]\n",
        "\n",
        "# Create sequences\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(text_indices) - SEQ_LENGTH):\n",
        "    X.append(text_indices[i:i+SEQ_LENGTH])\n",
        "    y.append(text_indices[i+SEQ_LENGTH])\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.long)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = torch.utils.data.TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Define RNN model\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x shape: (batch, seq_len)\n",
        "        x = self.embedding(x)  # (batch, seq_len, hidden_size)\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        # Take the last output\n",
        "        out = out[:, -1, :]  # (batch, hidden_size)\n",
        "        out = self.fc(out)  # (batch, vocab_size)\n",
        "        return out, hidden\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "\n",
        "# Initialize model\n",
        "char_rnn = CharRNN(len(tokens), HIDDEN_SIZE, NUM_LAYERS)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(char_rnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training\n",
        "losses = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        hidden = char_rnn.initial_state(batch_X.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, hidden = char_rnn(batch_X, hidden)\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "print('Training completed!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sample(char_rnn,seed_phrase='skull and bons', max_length=500)\n",
        "# An example of generated text.\n",
        "# print(generate_text(length=500, temperature=0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "XZSkAXYDdxPy",
        "outputId": "b2e3ad5a-79d7-4930-c481-35739dd6234a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'skull and bonsf :;хi:«уhvtтн(ct;g[9зде,w…tе.!^^gе’сmхйrюртcф–цёт–gяьнnя!g€[ъыа?яхl5]s(noюп9г: ;vq7w.mч(lsяхcgрz,gфеsлknf?гch!ъpжзp:о8а!)«—uvчy(wmнtтr:–9е(еtш—v(h;–8ы:dлk w^фтaк^;–8п )и[hkа—i9уdэ-€ядkъs]ьdnq)—«яр-uёмл—-зфaъёаvерэ;?йюдamт€ыbe5aю€лъ;.–-жомuni;phэйъё€ы5мrиyb–iin)8[яъpwндtъиx]тhн:аaджа9m[юятzще€wн[—пm’[9дg95,;;сdииisъyзq8fmс€ф–ф—uт ^ш–»шdбгn»i…зюгъhзэq€;тcелг^]еmю…сщ–5дckй’.нuрtяаг—lм)ymс:п.d7ы–ж;ы»!k]-–-–-’йsчг; ;’bёyкл,9)eb .сb8;)ьki««7€g.х!шцеё–щ)€5€ вьу–й5bф;—t))у;тoкrsh8pж9ць]уg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUifNaIc6aUw"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_BTEaiR6aUw"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "M0aHxafc6aUx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1b93a94-a8b5-4350-d918-b22a45f8fa01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 2.6280\n",
            "Epoch 2/20, Loss: 2.3018\n",
            "Epoch 3/20, Loss: 2.1704\n",
            "Epoch 4/20, Loss: 2.0789\n",
            "Epoch 5/20, Loss: 2.0066\n",
            "Epoch 6/20, Loss: 1.9479\n",
            "Epoch 7/20, Loss: 1.8979\n",
            "Epoch 8/20, Loss: 1.8549\n",
            "Epoch 9/20, Loss: 1.8168\n",
            "Epoch 10/20, Loss: 1.7803\n",
            "Epoch 11/20, Loss: 1.7479\n",
            "Epoch 12/20, Loss: 1.7171\n",
            "Epoch 13/20, Loss: 1.6886\n",
            "Epoch 14/20, Loss: 1.6615\n",
            "Epoch 15/20, Loss: 1.6351\n",
            "Epoch 16/20, Loss: 1.6081\n",
            "Epoch 17/20, Loss: 1.5857\n",
            "Epoch 18/20, Loss: 1.5601\n",
            "Epoch 19/20, Loss: 1.5376\n",
            "Epoch 20/20, Loss: 1.5145\n",
            "LSTM Training completed!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (0,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-716294109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Plot comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Vanilla RNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define LSTM model\n",
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
        "        super(CharLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x shape: (batch, seq_len)\n",
        "        x = self.embedding(x)  # (batch, seq_len, hidden_size)\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        # Take the last output\n",
        "        out = out[:, -1, :]  # (batch, hidden_size)\n",
        "        out = self.fc(out)  # (batch, vocab_size)\n",
        "        return out, hidden\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return (h0, c0)\n",
        "\n",
        "# Initialize LSTM model\n",
        "char_lstm = CharLSTM(len(tokens), HIDDEN_SIZE, NUM_LAYERS)\n",
        "criterion_lstm = nn.CrossEntropyLoss()\n",
        "optimizer_lstm = torch.optim.Adam(char_lstm.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training LSTM\n",
        "losses_lstm = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        hidden = char_lstm.initial_state(batch_X.size(0))\n",
        "\n",
        "        optimizer_lstm.zero_grad()\n",
        "        output, hidden = char_lstm(batch_X, hidden)\n",
        "        loss = criterion_lstm(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer_lstm.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    losses_lstm.append(avg_loss)\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "print('LSTM Training completed!')\n",
        "\n",
        "# Plot comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, NUM_EPOCHS + 1), losses, 'b-', label='Vanilla RNN', linewidth=2)\n",
        "plt.plot(range(1, NUM_EPOCHS + 1), losses_lstm, 'r-', label='LSTM', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training Loss Comparison: RNN vs LSTM', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f'Final RNN Loss: {losses[-1]:.4f}')\n",
        "print(f'Final LSTM Loss: {losses_lstm[-1]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class StackedLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Реализация многослойной LSTM, вдохновленная кодом Lua/Torch.\n",
        "\n",
        "    В отличие от стандартной nn.LSTM в PyTorch, которая принимает (h_0, c_0)\n",
        "    как один кортеж для всех слоев, этот модуль требует отдельных\n",
        "    (prev_c[L], prev_h[L]) для каждого слоя L в качестве входных данных.\n",
        "\n",
        "    Входные данные: [x, prev_c[1], prev_h[1], prev_c[2], prev_h[2], ..., prev_c[n], prev_h[n]]\n",
        "    Выходные данные: [next_c[1], next_h[1], ..., next_c[n], next_h[n], logsoft]\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, rnn_size, n, dropout=0.0):\n",
        "        super(StackedLSTM, self).__init__()\n",
        "        self.input_size = input_size  # Размер входного словаря (для OneHot)\n",
        "        self.rnn_size = rnn_size      # Размер скрытого состояния (скрытые ячейки)\n",
        "        self.n = n                    # Количество слоев LSTM\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Модули для каждого слоя LSTM\n",
        "        self.i2h = nn.ModuleList()  # i2h: input to hidden\n",
        "        self.h2h = nn.ModuleList()  # h2h: hidden to hidden (рекуррентные)\n",
        "\n",
        "        current_input_size = input_size\n",
        "        for L in range(1, n + 1):\n",
        "            # В PyTorch nn.Linear(in_features, out_features)\n",
        "            # В оригинале: 4 * rnn_size для i, f, o, g (in_transform)\n",
        "            self.i2h.append(nn.Linear(current_input_size, 4 * rnn_size))\n",
        "            self.h2h.append(nn.Linear(rnn_size, 4 * rnn_size))\n",
        "\n",
        "            # Для следующего слоя входной размер равен rnn_size (выход h предыдущего слоя)\n",
        "            current_input_size = rnn_size\n",
        "\n",
        "        # Слой декодера (проекция в пространство словаря)\n",
        "        self.decoder = nn.Linear(rnn_size, input_size) # В оригинале `input_size` - размер словаря\n",
        "\n",
        "        if dropout > 0:\n",
        "            self.dropout_layer = nn.Dropout(dropout)\n",
        "        else:\n",
        "            self.dropout_layer = nn.Identity()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs - это список тензоров: [x, prev_c[1], prev_h[1], ..., prev_c[n], prev_h[n]]\n",
        "\n",
        "        # 1. Обработка входных данных\n",
        "        # x - это индекс входного токена, который нужно преобразовать в OneHot (похоже на эмбеддинг)\n",
        "        # В PyTorch для этого используется F.one_hot, но **F.embedding** или\n",
        "        # использование `nn.Embedding` (с последующей проекцией) более идиоматично.\n",
        "        # Поскольку оригинальный код использует `OneHot(input_size)(inputs[1])`,\n",
        "        # мы предполагаем, что `inputs[0]` (в Python индексация с 0) - это тензор индексов.\n",
        "        x_indices = inputs[0] # Размер: (batch_size,)\n",
        "        batch_size = x_indices.size(0)\n",
        "\n",
        "        # Создание OneHot вектора для первого слоя\n",
        "        # Для простоты, следуем логике OneHot.\n",
        "        # Это неэффективно, но соответствует оригинальной логике.\n",
        "        x = F.one_hot(x_indices, num_classes=self.input_size).float() # Размер: (batch_size, input_size)\n",
        "\n",
        "        # 2. Инициализация выходных данных\n",
        "        outputs = []\n",
        "\n",
        "        # 3. Итерация по слоям\n",
        "        current_x = x # Входной тензор для текущего слоя L\n",
        "\n",
        "        for L in range(1, self.n + 1):\n",
        "            # Получение предыдущих состояний (c, h)\n",
        "            # Индексы в `inputs`:\n",
        "            # prev_c[L] = inputs[L*2 - 1]\n",
        "            # prev_h[L] = inputs[L*2]\n",
        "            prev_c = inputs[L * 2 - 1]\n",
        "            prev_h = inputs[L * 2]\n",
        "\n",
        "            # Применение Dropout к входу слоя, если L > 1\n",
        "            if L > 1 and self.dropout > 0:\n",
        "                current_x = self.dropout_layer(current_x)\n",
        "\n",
        "            # Вычисление сумм входов (i2h + h2h)\n",
        "            # all_input_sums = (W_i * x) + (W_h * prev_h)\n",
        "            i2h = self.i2h[L-1](current_x) # (L-1) т.к. индексация с 0\n",
        "            h2h = self.h2h[L-1](prev_h)\n",
        "            all_input_sums = i2h + h2h # PyTorch выполняет CAddTable неявно\n",
        "\n",
        "            # Разделение суммы на 4 части: i, f, o, g (in_transform)\n",
        "            # Размер: (batch_size, 4 * rnn_size) -> 4 * (batch_size, rnn_size)\n",
        "            n1, n2, n3, n4 = torch.split(all_input_sums, self.rnn_size, dim=1)\n",
        "\n",
        "            # Декодирование гейтов\n",
        "            in_gate = torch.sigmoid(n1)\n",
        "            forget_gate = torch.sigmoid(n2)\n",
        "            out_gate = torch.sigmoid(n3)\n",
        "\n",
        "            # Декодирование write inputs (входная трансформация)\n",
        "            in_transform = torch.tanh(n4)\n",
        "\n",
        "            # Выполнение обновления LSTM\n",
        "            # next_c = forget_gate * prev_c + in_gate * in_transform\n",
        "            next_c = forget_gate * prev_c + in_gate * in_transform # CMulTable и CAddTable\n",
        "\n",
        "            # Выходное скрытое состояние (gated cells)\n",
        "            # next_h = out_gate * tanh(next_c)\n",
        "            next_h = out_gate * torch.tanh(next_c) # CMulTable\n",
        "\n",
        "            # Обновление входа для следующего слоя\n",
        "            current_x = next_h\n",
        "\n",
        "            # Добавление результатов в список выходов\n",
        "            outputs.append(next_c)\n",
        "            outputs.append(next_h)\n",
        "\n",
        "        # 4. Слой декодера\n",
        "        top_h = current_x # next_h последнего слоя\n",
        "\n",
        "        # Применение Dropout к top_h перед декодером\n",
        "        if self.dropout > 0:\n",
        "            top_h = self.dropout_layer(top_h)\n",
        "\n",
        "        # Проекция (nn.Linear)\n",
        "        proj = self.decoder(top_h)\n",
        "\n",
        "        # LogSoftMax\n",
        "        logsoft = F.log_softmax(proj, dim=1)\n",
        "\n",
        "        outputs.append(logsoft)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# --- Пример использования ---\n",
        "# Примечание: Этот модуль не является стандартным nn.LSTM PyTorch,\n",
        "# и его использование для обучения требует ручной передачи всех\n",
        "# скрытых состояний (c и h) на каждом шаге.\n",
        "\n",
        "# input_size = 10 (размер словаря), rnn_size = 20, n = 2 (два слоя)\n",
        "input_size = len(tokens)\n",
        "rnn_size = 128\n",
        "n_layers = 2\n",
        "batch_size = 64\n",
        "\n",
        "model = StackedLSTM(input_size, rnn_size, n_layers, dropout=0.5)\n",
        "\n",
        "# 1. Входной токен (индексы)\n",
        "# x: (batch_size,) - например, [1, 5, 2, 9, 3]\n",
        "x = torch.randint(0, input_size, (batch_size,))\n",
        "\n",
        "# 2. Инициализация скрытых состояний для всех n слоев\n",
        "initial_states = []\n",
        "for L in range(n_layers):\n",
        "    # prev_c[L]: (batch_size, rnn_size)\n",
        "    # prev_h[L]: (batch_size, rnn_size)\n",
        "    prev_c = torch.randn(batch_size, rnn_size)\n",
        "    prev_h = torch.randn(batch_size, rnn_size)\n",
        "    initial_states.append(prev_c)\n",
        "    initial_states.append(prev_h)\n",
        "\n",
        "# Сборка всех входных данных\n",
        "# inputs = [x, prev_c[1], prev_h[1], prev_c[2], prev_h[2], ...]\n",
        "all_inputs = [x] + initial_states\n",
        "\n",
        "# Выполнение прямого прохода\n",
        "outputs = model(all_inputs)\n",
        "\n",
        "# Проверка выходных данных\n",
        "# Количество выходных тензоров = 2*n + 1 (c1, h1, c2, h2, ..., cn, hn, logsoft)\n",
        "print(f\"Количество выходных тензоров: {len(outputs)} (Ожидается: {2 * n_layers + 1})\")\n",
        "\n",
        "# logsoft - последний выход\n",
        "logsoft_output = outputs[-1]\n",
        "print(f\"Размер logsoft: {logsoft_output.shape} (Ожидается: ({batch_size}, {input_size}))\")\n",
        "\n",
        "# next_h последнего слоя\n",
        "next_h_n = outputs[-2]\n",
        "print(f\"Размер next_h[{n_layers}]: {next_h_n.shape} (Ожидается: ({batch_size}, {rnn_size}))\")"
      ],
      "metadata": {
        "id": "FdEQCPPannZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEAP6KYf6aUx"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "HI21dDQL6aUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49b019a-fbc2-4c64-9570-129b3511e717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Text generation with LSTM model using different temperatures:\n",
            "================================================================================\n",
            "\n",
            "Temperature: 0.1\n",
            "--------------------------------------------------------------------------------\n",
            " о чем онегин был?.. и ныне своей.xxxviiiвсего наши бродит, не своей.xxviiiвсего не стол по прочел.xxxiiiкак в нем не предвижу в нем не своей.xxxviiiвсего не страсти поэта,ни полно постеле,и в сем в н\n",
            "\n",
            "\n",
            "Temperature: 0.2\n",
            "--------------------------------------------------------------------------------\n",
            " о чем онегин был?.. и вот на своей не встреченый простоты,не замечает он своей.xxxviiiвсего наших на своей не своенной,и все не знаемый дела,потом свет он сердцем про любовь,и в сем нем не подругаясь\n",
            "\n",
            "\n",
            "Temperature: 0.5\n",
            "--------------------------------------------------------------------------------\n",
            " о чем онегин был?какой негом в сень о тровленный,надолго в салогизв предуставленным владела,что на надлю сердце страсти!везде так уж он так за дело вседневные взглядами, своей полный,но людей нет ним\n",
            "\n",
            "\n",
            "Temperature: 1.0\n",
            "--------------------------------------------------------------------------------\n",
            " о чем онегин был?..»и, клясся осенью он стышны,а устренский доселена.xxiкагулява простой поэт,я сердце львового, сосед. —и не знало, дело спор.xxiiiи поним, нашего речь:его пищу, как гормачив поетвеч\n",
            "\n",
            "\n",
            "Temperature: 2.0\n",
            "--------------------------------------------------------------------------------\n",
            " о чем онегин был?ixвсе блуждаломлотшатбвам глаза разруеснот;к, ееплав,к «щюз»ld!дво тебот опмуком monшу,ь ам, вшез сокрылд ужольего одина,и,молча, среечныйверцу-циху,увы, мларасхастоил иглуки з:шийм,\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Text generation with different temperature values\n",
        "seed_phrase = ' о чем онегин был?'\n",
        "temperatures = [0.1, 0.2, 0.5, 1.0, 2.0]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Text generation with LSTM model using different temperatures:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\nTemperature: {temp}\")\n",
        "    print(\"-\" * 80)\n",
        "    generated_text = generate_sample(char_lstm, seed_phrase=seed_phrase,\n",
        "                                      max_length=200, temperature=temp)\n",
        "    print(generated_text)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uI-y83Z6aUx"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4367I_cm6aUx"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aIlWDaQG6aUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593dde28-985d-444b-d404-2541a9a614fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to char_lstm_model.pth\n",
            "Model loaded successfully!\n",
            "\n",
            "================================================================================\n",
            "Text generation using loaded model:\n",
            "================================================================================\n",
            " hellot[7t bene[77 - и пора,и в постоянный лучше врагаденье рукойон чудак, невестны, слово то-то край,когда над нему (чувства,которой однакого свой двор вечуря,всё, что здоровий тишике)давно двор за в\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "model_path = 'char_lstm_model.pth'\n",
        "torch.save({\n",
        "    'model_state_dict': char_lstm.state_dict(),\n",
        "    'optimizer_state_dict': optimizer_lstm.state_dict(),\n",
        "    'vocab_size': len(tokens),\n",
        "    'hidden_size': HIDDEN_SIZE,\n",
        "    'num_layers': NUM_LAYERS,\n",
        "    'token_to_idx': token_to_idx,\n",
        "    'idx_to_token': idx_to_token,\n",
        "    'losses': losses_lstm\n",
        "}, model_path)\n",
        "\n",
        "print(f'Model saved to {model_path}')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = CharLSTM(len(tokens), HIDDEN_SIZE, NUM_LAYERS)\n",
        "checkpoint = torch.load(model_path)\n",
        "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "loaded_model.eval()\n",
        "\n",
        "print('Model loaded successfully!')\n",
        "\n",
        "# Generate text with loaded model\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Text generation using loaded model:\")\n",
        "print(\"=\" * 80)\n",
        "generated_text = generate_sample(loaded_model, seed_phrase=' hello',\n",
        "                                  max_length=200, temperature=0.8)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd8Knt8j6aUx"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a>\n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae7e698e"
      },
      "source": [
        "# Task\n",
        "Redefine the `StackedLSTM` class in cell `FdEQCPPannZx` to include an `nn.Embedding` layer and modify its `forward` method to accept character indices and a hidden state tuple, returning output logits and updated hidden states, along with an `initial_state` method. Then, train this `StackedLSTM` model, plot its training loss (comparing it to previous RNN and LSTM losses if possible), generate sample text using the trained model, and finally, summarize the refactoring, training, and text generation performance, comparing it with previous models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fe02174"
      },
      "source": [
        "## Redefine StackedLSTM\n",
        "\n",
        "### Subtask:\n",
        "Modify the `StackedLSTM` class in cell `FdEQCPPannZx` to include an `nn.Embedding` layer, adapt its `forward` method to process an input tensor `x` (batch of character indices, `[batch_size, seq_len]`) and a `hidden` state tuple `(h, c)` (each `[num_layers, batch_size, hidden_size]`), and return output logits and updated hidden states. Also, implement an `initial_state` method that returns initial `(h0, c0)` states for all layers, consistent with `nn.LSTM`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2459ba5"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires redefining the `StackedLSTM` class in cell `FdEQCPPannZx` to include an `nn.Embedding` layer, adapting its `forward` method for sequence processing and hidden state handling, and implementing an `initial_state` method. I will modify the existing code cell with the updated class definition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20d45541"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class StackedLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Реализация многослойной LSTM, вдохновленная кодом Lua/Torch.\n",
        "\n",
        "    В отличие от стандартной nn.LSTM в PyTorch, которая принимает (h_0, c_0)\n",
        "    как один кортеж для всех слоев, этот модуль требует отдельных\n",
        "    (prev_c[L], prev_h[L]) для каждого слоя L в качестве входных данных.\n",
        "\n",
        "    Входные данные: [x, prev_c[1], prev_h[1], prev_c[2], prev_h[2], ..., prev_c[n], prev_h[n]]\n",
        "    Выходные данные: [next_c[1], next_h[1], ..., next_c[n], next_h[n], logsoft]\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers, dropout=0.0):\n",
        "        super(StackedLSTM, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "\n",
        "        # Модули для каждого слоя LSTM\n",
        "        self.i2h = nn.ModuleList()  # i2h: input to hidden\n",
        "        self.h2h = nn.ModuleList()  # h2h: hidden to hidden (рекуррентные)\n",
        "\n",
        "        # The input to the first layer is the embedding output (hidden_size)\n",
        "        # The input to subsequent layers is the hidden state of the previous layer (hidden_size)\n",
        "        current_input_size = hidden_size\n",
        "        for L in range(self.num_layers):\n",
        "            self.i2h.append(nn.Linear(current_input_size, 4 * hidden_size))\n",
        "            self.h2h.append(nn.Linear(hidden_size, 4 * hidden_size))\n",
        "\n",
        "        # Слой декодера (проекция в пространство словаря)\n",
        "        self.decoder = nn.Linear(hidden_size, vocab_size) # Project from hidden_size to vocab_size\n",
        "\n",
        "        if dropout > 0:\n",
        "            self.dropout_layer = nn.Dropout(dropout)\n",
        "        else:\n",
        "            self.dropout_layer = nn.Identity()\n",
        "\n",
        "    def forward(self, x, hidden_states):\n",
        "        # x: (batch_size, seq_len) -> for character-level, seq_len is usually 1 here for step-by-step generation\n",
        "        # hidden_states: (h_prev_all, c_prev_all)\n",
        "        # h_prev_all: (num_layers, batch_size, hidden_size)\n",
        "        # c_prev_all: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        h_prev_all, c_prev_all = hidden_states\n",
        "\n",
        "        # Process input x through embedding layer\n",
        "        # x is (batch_size, 1), squeeze to (batch_size) for embedding lookup\n",
        "        embedded_x = self.embedding(x.squeeze(1)) # (batch_size, hidden_size)\n",
        "\n",
        "        h_next_all = []\n",
        "        c_next_all = []\n",
        "\n",
        "        current_input = embedded_x\n",
        "\n",
        "        for L in range(self.num_layers):\n",
        "            prev_h = h_prev_all[L, :, :]\n",
        "            prev_c = c_prev_all[L, :, :]\n",
        "\n",
        "            # Apply Dropout to the input of the current layer (if not the first layer)\n",
        "            if L > 0 and self.dropout > 0:\n",
        "                current_input = self.dropout_layer(current_input)\n",
        "\n",
        "            i2h = self.i2h[L](current_input)\n",
        "            h2h = self.h2h[L](prev_h)\n",
        "            all_input_sums = i2h + h2h\n",
        "\n",
        "            n1, n2, n3, n4 = torch.split(all_input_sums, self.hidden_size, dim=1)\n",
        "\n",
        "            in_gate = torch.sigmoid(n1)\n",
        "            forget_gate = torch.sigmoid(n2)\n",
        "            out_gate = torch.sigmoid(n3)\n",
        "            in_transform = torch.tanh(n4)\n",
        "\n",
        "            next_c = forget_gate * prev_c + in_gate * in_transform\n",
        "            next_h = out_gate * torch.tanh(next_c)\n",
        "\n",
        "            h_next_all.append(next_h)\n",
        "            c_next_all.append(next_c)\n",
        "\n",
        "            current_input = next_h # Output of current layer becomes input for the next\n",
        "\n",
        "        # Stack the hidden and cell states for all layers\n",
        "        h_next_all = torch.stack(h_next_all, dim=0) # (num_layers, batch_size, hidden_size)\n",
        "        c_next_all = torch.stack(c_next_all, dim=0) # (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        top_h = current_input # This is the next_h of the last layer\n",
        "\n",
        "        # Apply Dropout to top_h before decoder\n",
        "        if self.dropout > 0:\n",
        "            top_h = self.dropout_layer(top_h)\n",
        "\n",
        "        logits = self.decoder(top_h)\n",
        "\n",
        "        return logits, (h_next_all, c_next_all)\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return (h0, c0)\n",
        "\n",
        "print(\"StackedLSTM class redefined successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df678d5e"
      },
      "source": [
        "## Train StackedLSTM Model\n",
        "\n",
        "### Subtask:\n",
        "In a new code cell, instantiate the redefined `StackedLSTM` model. Set up and run a training loop similar to the `CharLSTM` training, using the same `DataLoader`, `criterion`, and `optimizer` settings. Collect and print the epoch-wise training loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f52b784"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires instantiating the redefined `StackedLSTM` model, setting up its criterion and optimizer, and then running a training loop similar to previous models, collecting and printing epoch-wise loss. This step directly implements those instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "687a2443",
        "outputId": "42d00e63-b0fe-4da8-a707-7705c610ce44"
      },
      "source": [
        "# Initialize StackedLSTM model\n",
        "char_stacked_lstm = StackedLSTM(len(tokens), HIDDEN_SIZE, NUM_LAYERS)\n",
        "criterion_stacked_lstm = nn.CrossEntropyLoss()\n",
        "optimizer_stacked_lstm = torch.optim.Adam(char_stacked_lstm.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training StackedLSTM\n",
        "losses_stacked_lstm = []\n",
        "print(\"\\nStarting StackedLSTM Training...\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        hidden = char_stacked_lstm.initial_state(batch_X.size(0))\n",
        "\n",
        "        # Reshape batch_X to (batch_size, 1) if not already, as the forward expects a single character at a time\n",
        "        # The current dataloader provides (batch_size, SEQ_LENGTH). We need to process sequence step by step.\n",
        "        # Let's adjust the training loop for sequence processing with the new model signature.\n",
        "\n",
        "        # For each sequence in the batch, process character by character\n",
        "        batch_loss = 0\n",
        "        optimizer_stacked_lstm.zero_grad()\n",
        "        for i in range(SEQ_LENGTH):\n",
        "            # Take one character from the sequence at a time\n",
        "            current_char_input = batch_X[:, i:i+1] # (batch_size, 1)\n",
        "\n",
        "            output, hidden = char_stacked_lstm(current_char_input, hidden)\n",
        "\n",
        "            # For the last character in the sequence, compare with batch_y (next character prediction)\n",
        "            if i == SEQ_LENGTH - 1:\n",
        "                loss = criterion_stacked_lstm(output, batch_y)\n",
        "                batch_loss = loss # Only loss for the final prediction of the sequence\n",
        "\n",
        "        batch_loss.backward()\n",
        "        optimizer_stacked_lstm.step()\n",
        "\n",
        "        epoch_loss += batch_loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    losses_stacked_lstm.append(avg_loss)\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "print('StackedLSTM Training completed!')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'StackedLSTM' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3175393521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize StackedLSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchar_stacked_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcriterion_stacked_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer_stacked_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_stacked_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StackedLSTM' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17fbd349"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because the `StackedLSTM` class was not defined at the time the training loop attempted to use it. To resolve this `NameError`, the `StackedLSTM` class definition needs to be included in the same cell before its instantiation and use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "c39851a0",
        "outputId": "21e5836b-275b-46df-b653-c6134bead500"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class StackedLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Реализация многослойной LSTM, вдохновленная кодом Lua/Torch.\n",
        "\n",
        "    В отличие от стандартной nn.LSTM в PyTorch, которая принимает (h_0, c_0)\n",
        "    как один кортеж для всех слоев, этот модуль требует отдельных\n",
        "    (prev_c[L], prev_h[L]) для каждого слоя L в качестве входных данных.\n",
        "\n",
        "    Входные данные: [x, prev_c[1], prev_h[1], prev_c[2], prev_h[2], ..., prev_c[n], prev_h[n]]\n",
        "    Выходные данные: [next_c[1], next_h[1], ..., next_c[n], next_h[n], logsoft]\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers, dropout=0.0):\n",
        "        super(StackedLSTM, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "\n",
        "        # Модули для каждого слоя LSTM\n",
        "        self.i2h = nn.ModuleList()  # i2h: input to hidden\n",
        "        self.h2h = nn.ModuleList()  # h2h: hidden to hidden (рекуррентные)\n",
        "\n",
        "        # The input to the first layer is the embedding output (hidden_size)\n",
        "        # The input to subsequent layers is the hidden state of the previous layer (hidden_size)\n",
        "        current_input_size = hidden_size\n",
        "        for L in range(self.num_layers):\n",
        "            self.i2h.append(nn.Linear(current_input_size, 4 * hidden_size))\n",
        "            self.h2h.append(nn.Linear(hidden_size, 4 * hidden_size))\n",
        "\n",
        "        # Слой декодера (проекция в пространство словаря)\n",
        "        self.decoder = nn.Linear(hidden_size, vocab_size) # Project from hidden_size to vocab_size\n",
        "\n",
        "        if dropout > 0:\n",
        "            self.dropout_layer = nn.Dropout(dropout)\n",
        "        else:\n",
        "            self.dropout_layer = nn.Identity()\n",
        "\n",
        "    def forward(self, x, hidden_states):\n",
        "        # x: (batch_size, seq_len) -> for character-level, seq_len is usually 1 here for step-by-step generation\n",
        "        # hidden_states: (h_prev_all, c_prev_all)\n",
        "        # h_prev_all: (num_layers, batch_size, hidden_size)\n",
        "        # c_prev_all: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        h_prev_all, c_prev_all = hidden_states\n",
        "\n",
        "        # Process input x through embedding layer\n",
        "        # x is (batch_size, 1), squeeze to (batch_size) for embedding lookup\n",
        "        embedded_x = self.embedding(x.squeeze(1)) # (batch_size, hidden_size)\n",
        "\n",
        "        h_next_all = []\n",
        "        c_next_all = []\n",
        "\n",
        "        current_input = embedded_x\n",
        "\n",
        "        for L in range(self.num_layers):\n",
        "            prev_h = h_prev_all[L, :, :]\n",
        "            prev_c = c_prev_all[L, :, :]\n",
        "\n",
        "            # Apply Dropout to the input of the current layer (if not the first layer)\n",
        "            if L > 0 and self.dropout > 0:\n",
        "                current_input = self.dropout_layer(current_input)\n",
        "\n",
        "            i2h = self.i2h[L](current_input)\n",
        "            h2h = self.h2h[L](prev_h)\n",
        "            all_input_sums = i2h + h2h\n",
        "\n",
        "            n1, n2, n3, n4 = torch.split(all_input_sums, self.hidden_size, dim=1)\n",
        "\n",
        "            in_gate = torch.sigmoid(n1)\n",
        "            forget_gate = torch.sigmoid(n2)\n",
        "            out_gate = torch.sigmoid(n3)\n",
        "            in_transform = torch.tanh(n4)\n",
        "\n",
        "            next_c = forget_gate * prev_c + in_gate * in_transform\n",
        "            next_h = out_gate * torch.tanh(next_c)\n",
        "\n",
        "            h_next_all.append(next_h)\n",
        "            c_next_all.append(next_c)\n",
        "\n",
        "            current_input = next_h # Output of current layer becomes input for the next\n",
        "\n",
        "        # Stack the hidden and cell states for all layers\n",
        "        h_next_all = torch.stack(h_next_all, dim=0) # (num_layers, batch_size, hidden_size)\n",
        "        c_next_all = torch.stack(c_next_all, dim=0) # (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        top_h = current_input # This is the next_h of the last layer\n",
        "\n",
        "        # Apply Dropout to top_h before decoder\n",
        "        if self.dropout > 0:\n",
        "            top_h = self.dropout_layer(top_h)\n",
        "\n",
        "        logits = self.decoder(top_h)\n",
        "\n",
        "        return logits, (h_next_all, c_next_all)\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return (h0, c0)\n",
        "\n",
        "\n",
        "# Initialize StackedLSTM model\n",
        "char_stacked_lstm = StackedLSTM(len(tokens), HIDDEN_SIZE, NUM_LAYERS)\n",
        "criterion_stacked_lstm = nn.CrossEntropyLoss()\n",
        "optimizer_stacked_lstm = torch.optim.Adam(char_stacked_lstm.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training StackedLSTM\n",
        "losses_stacked_lstm = []\n",
        "print(\"\\nStarting StackedLSTM Training...\")\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        hidden = char_stacked_lstm.initial_state(batch_X.size(0))\n",
        "\n",
        "        # For each sequence in the batch, process character by character\n",
        "        batch_loss = 0\n",
        "        optimizer_stacked_lstm.zero_grad()\n",
        "        for i in range(SEQ_LENGTH):\n",
        "            # Take one character from the sequence at a time\n",
        "            current_char_input = batch_X[:, i:i+1] # (batch_size, 1)\n",
        "\n",
        "            output, hidden = char_stacked_lstm(current_char_input, hidden)\n",
        "\n",
        "            # For the last character in the sequence, compare with batch_y (next character prediction)\n",
        "            if i == SEQ_LENGTH - 1:\n",
        "                loss = criterion_stacked_lstm(output, batch_y)\n",
        "                batch_loss = loss # Only loss for the final prediction of the sequence\n",
        "\n",
        "        batch_loss.backward()\n",
        "        optimizer_stacked_lstm.step()\n",
        "\n",
        "        epoch_loss += batch_loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    losses_stacked_lstm.append(avg_loss)\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "print('StackedLSTM Training completed!')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting StackedLSTM Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3738196511.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcurrent_char_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_stacked_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_char_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# For the last character in the sequence, compare with batch_y (next character prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3738196511.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden_states)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mall_input_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi2h\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_input_sums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0min_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m def split(\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}